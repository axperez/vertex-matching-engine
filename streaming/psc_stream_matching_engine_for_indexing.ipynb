{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Create Vertex AI Matching Engine index - Streaming w/ PSC\n",
    "![ ](https://www.google-analytics.com/collect?v=2&tid=G-L6X3ECH596&cid=1&en=page_view&sid=1&dt=sdk_matching_engine_for_indexing.ipynb&dl=notebooks%2Fofficial%2Fmatching_engine%2Fsdk_matching_engine_for_indexing.ipynb)\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "      <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0a74aaf1481"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This example demonstrates how to use the Vertex AI ANN Service. It is a high scale, low latency solution, to find similar vectors (or more specifically \"embeddings\") for a large corpus. Moreover, it is a fully managed offering, further reducing operational overhead. It is built upon [Approximate Nearest Neighbor (ANN) technology](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) developed by Google Research.\n",
    "\n",
    "Learn more about [Vertex AI Matching Engine](https://cloud.google.com/vertex-ai/docs/matching-engine/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34a4b245e795"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, you learn how to create Approximate Nearest Neighbor (ANN) Index, query against indexes, and validate the performance of the index. \n",
    "\n",
    "This tutorial uses the following Google Cloud ML services:\n",
    "\n",
    "- `Vertex AI Matching Engine`\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "* Create ANN Index and Brute Force Index\n",
    "* Create an IndexEndpoint with Private Service Connect (PSC)\n",
    "* Deploy ANN Index and Brute Force Index\n",
    "* Perform online query\n",
    "* Compute recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used for this tutorial is the [GloVe dataset](https://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "\"GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Workbench Instance with Conda Env as Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Vertex Workbench Instance [here](https://console.cloud.google.com/vertex-ai/workbench/instances/create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new conda environment to use as a jupyter kernel\n",
    "\n",
    "Run the following commands in the terminal of your Vertex Workbench Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new conda environment with Python 3.10 and ipykernel\n",
    "```bash\n",
    "CONDA_ENV_NAME=\"vme\"\n",
    "conda create -n $CONDA_ENV_NAME python=3.10 ipykernel\n",
    "```\n",
    "2. Change the display name of the jupyter kernel to Python 3 (env_name)\n",
    "```bash\n",
    "mv /opt/conda/envs/$CONDA_ENV_NAME/share/jupyter/kernels/python3/kernel.json /tmp/temp.json && jq -r '.display_name |= \"Python 3 ('$CONDA_ENV_NAME')\"' /tmp/temp.json > /opt/conda/envs/$CONDA_ENV_NAME/share/jupyter/kernels/python3/kernel.json && rm /tmp/temp.json\n",
    "```\n",
    "3. Deactivate conda environment\n",
    "```bash\n",
    "conda deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select your new jupyter kernel for this jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0f1bea346db"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the latest version of Cloud Storage, BigQuery and Vertex AI SDKs for Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irSMQn6gZ19l"
   },
   "source": [
    "Install the `h5py` to prepare sample dataset, and the `grpcio-tools` for querying against the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfbccc635a17",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                        google-cloud-storage \\\n",
    "                        grpcio-tools \\\n",
    "                        h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd28c9e4f067"
   },
   "source": [
    "## Before you begin\n",
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "80c0215f05a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! echo Y | gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f4512bf63b3"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "474be5183c27"
   },
   "outputs": [],
   "source": [
    "REGION = \"\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "949271bfebe3"
   },
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b65b4ce80d9a"
   },
   "source": [
    "**1. Vertex AI Workbench**\n",
    "* Do nothing as you are already authenticated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "985cdbfe7372"
   },
   "source": [
    "**2. Local JupyterLab instance, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fbc9cd30cc4b"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79efab26ad02"
   },
   "source": [
    "**3. Colab, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a336a05c6149"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c0a44fa330f"
   },
   "source": [
    "**4. Service account or other**\n",
    "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5de53b31bf1"
   },
   "source": [
    "## Make sure the following cells are run from inside the VPC network that you created in the previous step.\n",
    "\n",
    "* **WARNING:** The MatchingIndexEndpoint.match method (to create online queries against your deployed index) has to be executed in a Vertex AI Workbench notebook instance that is created with the following requirements:\n",
    "  * **In the same region as where your ANN service is deployed** (for example, if you set `REGION = \"us-central1\"` as same as the tutorial, the notebook instance has to be in `us-central1`).\n",
    "  * If you run it in the colab or a Vertex AI Workbench notebook instance in a different VPC network or region, \"Create Online Queries\" section will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR6Wwv-hCCN-"
   },
   "source": [
    "## Prepare the data\n",
    "\n",
    "The GloVe dataset consists of a set of pre-trained embeddings. The embeddings are split into a \"train\" split, and a \"test\" split.\n",
    "We will create a vector search index from the \"train\" split, and use the embedding vectors in the \"test\" split as query vectors to test the vector search index.\n",
    "\n",
    "**Note:** While the data split uses the term \"train\", these are pre-trained embeddings and therefore are ready to be indexed for search. The terms \"train\" and \"test\" split are used just to be consistent with machine learning terminology.\n",
    "\n",
    "Download the GloVe dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wzS85TeB9dG"
   },
   "outputs": [],
   "source": [
    "! gsutil -m cp gs://cloud-samples-data/vertex-ai/matching_engine/glove-100-angular.hdf5 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fAO9CMoCNtq"
   },
   "source": [
    "Read the data into memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lZ3JQTS6CN-3"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# The number of nearest neighbors to be retrieved from database for each query.\n",
    "NUM_NEIGHBOURS = 10\n",
    "\n",
    "h5 = h5py.File(\"glove-100-angular.hdf5\", \"r\")\n",
    "train = h5[\"train\"]\n",
    "test = h5[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pE6bBBo7GjJK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11333  ,  0.48402  ,  0.090771 , -0.22439  ,  0.034206 ,\n",
       "       -0.55831  ,  0.041849 , -0.53573  ,  0.18809  , -0.58722  ,\n",
       "        0.015313 , -0.014555 ,  0.80842  , -0.038519 ,  0.75348  ,\n",
       "        0.70502  , -0.17863  ,  0.3222   ,  0.67575  ,  0.67198  ,\n",
       "        0.26044  ,  0.4187   , -0.34122  ,  0.2286   , -0.53529  ,\n",
       "        1.2582   , -0.091543 ,  0.19716  , -0.037454 , -0.3336   ,\n",
       "        0.31399  ,  0.36488  ,  0.71263  ,  0.1307   , -0.24654  ,\n",
       "       -0.52445  , -0.036091 ,  0.55068  ,  0.10017  ,  0.48095  ,\n",
       "        0.71104  , -0.053462 ,  0.22325  ,  0.30917  , -0.39926  ,\n",
       "        0.036634 , -0.35431  , -0.42795  ,  0.46444  ,  0.25586  ,\n",
       "        0.68257  , -0.20821  ,  0.38433  ,  0.055773 , -0.2539   ,\n",
       "       -0.20804  ,  0.52522  , -0.11399  , -0.3253   , -0.44104  ,\n",
       "        0.17528  ,  0.62255  ,  0.50237  , -0.7607   , -0.071786 ,\n",
       "        0.0080131, -0.13286  ,  0.50097  ,  0.18824  , -0.54722  ,\n",
       "       -0.42664  ,  0.4292   ,  0.14877  , -0.0072514, -0.16484  ,\n",
       "       -0.059798 ,  0.9895   , -0.61738  ,  0.054169 ,  0.48424  ,\n",
       "       -0.35084  , -0.27053  ,  0.37829  ,  0.11503  , -0.39613  ,\n",
       "        0.24266  ,  0.39147  , -0.075256 ,  0.65093  , -0.20822  ,\n",
       "       -0.17456  ,  0.53571  , -0.16537  ,  0.13582  , -0.56016  ,\n",
       "        0.016964 ,  0.1277   ,  0.94071  , -0.22608  , -0.021106 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQIQSyF9GtSv"
   },
   "source": [
    "#### Save the train split in JSONL format.\n",
    "\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as a JSON string on its own line.\n",
    "\n",
    "Additionally, to demonstrate the filtering functionality, the `restricts` key is set such that each embedding has a different `class`, `even` or `odd`. These are used during the later matching step to filter for results.\n",
    "See additional information of filtering here: https://cloud.google.com/vertex-ai/docs/matching-engine/filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "57fe2ce4b50f"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"glove100.json\", \"w\") as f:\n",
    "    embeddings_formatted = [\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"id\": str(index),\n",
    "                \"embedding\": [str(value) for value in embedding],\n",
    "                \"restricts\": [\n",
    "                    {\n",
    "                        \"namespace\": \"class\",\n",
    "                        \"allow\": [\"even\" if index % 2 == 0 else \"odd\"],\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        + \"\\n\"\n",
    "        for index, embedding in enumerate(train)\n",
    "    ]\n",
    "    f.writelines(embeddings_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuVl8DrWG8NS"
   },
   "source": [
    "Upload the training data to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PgsA_vbI8Vg"
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/matching_engine/initial/\"\n",
    "! gsutil -m cp glove100.json {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mglUPwHpJH98"
   },
   "source": [
    "## Create Indexes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhIBCQ7dDSbW"
   },
   "source": [
    "### Create ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qiIg9b5zJLi1"
   },
   "outputs": [],
   "source": [
    "DIMENSIONS = 100\n",
    "DISPLAY_NAME = \"stream_glove_100_1\"\n",
    "DISPLAY_NAME_BRUTE_FORCE = DISPLAY_NAME + \"_brute_force\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svLYiDf0OD2G"
   },
   "source": [
    "Create the ANN index configuration:\n",
    "\n",
    "To learn more about configuring the index, see [Input data format and structure](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup/format-structure).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = aiplatform_v1.IndexServiceClient(\n",
    "    client_options=dict(api_endpoint=ENDPOINT)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See shard size details (`SHARD_SIZE_SMALL`, `SHARD_SIZE_MEDIUM`, `SHARD_SIZE_LARGE`) in the [documentation](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index#create-index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeAhConfig = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"leafNodeEmbeddingCount\": struct_pb2.Value(number_value=500),\n",
    "        \"leafNodesToSearchPercent\": struct_pb2.Value(number_value=7),\n",
    "    }\n",
    ")\n",
    "\n",
    "algorithmConfig = struct_pb2.Struct(\n",
    "    fields={\"treeAhConfig\": struct_pb2.Value(struct_value=treeAhConfig)}\n",
    ")\n",
    "\n",
    "config = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"dimensions\": struct_pb2.Value(number_value=DIMENSIONS),\n",
    "        \"approximateNeighborsCount\": struct_pb2.Value(number_value=150),\n",
    "        \"distanceMeasureType\": struct_pb2.Value(string_value=\"DOT_PRODUCT_DISTANCE\"),\n",
    "        \"algorithmConfig\": struct_pb2.Value(struct_value=algorithmConfig),\n",
    "        \"shardSize\": struct_pb2.Value(string_value=\"SHARD_SIZE_SMALL\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"config\": struct_pb2.Value(struct_value=config),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(string_value=EMBEDDINGS_INITIAL_URI),\n",
    "    }\n",
    ")\n",
    "\n",
    "ann_index = {\n",
    "    \"display_name\": DISPLAY_NAME,\n",
    "    \"description\": \"Glove 100 ANN index - stream\",\n",
    "    \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "    \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.STREAM_UPDATE,\n",
    "}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index = index_client.create_index(parent=PARENT, index=ann_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_RESOURCE_NAME = ann_index.result().name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already created an index, set the index resource name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDEX_RESOURCE_NAME=\"1058864881920376832\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f1a9fbecabb"
   },
   "source": [
    "Using the resource name, you can retrieve an existing MatchingEngineIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "1ddb70647d98"
   },
   "outputs": [],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSsqZuyoA1SG"
   },
   "source": [
    "### Create Brute Force Index (for Ground Truth)\n",
    "\n",
    "The brute force index uses a naive brute force method to find the nearest neighbors. This method is not fast or efficient. Hence brute force indices are not recommended for production usage. They are to be used to find the \"ground truth\" set of neighbors, so that the \"ground truth\" set can be used to measure recall of the indices being tuned for production usage. To ensure an apples to apples comparison, the `distanceMeasureType` and `dimensions` of the brute force index should match those of the production indices being tuned.\n",
    "\n",
    "Create the brute force index configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithmConfig = struct_pb2.Struct(\n",
    "    fields={\"bruteForceConfig\": struct_pb2.Value(struct_value={})}\n",
    ")\n",
    "\n",
    "config = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"dimensions\": struct_pb2.Value(number_value=DIMENSIONS),\n",
    "        \"approximateNeighborsCount\": struct_pb2.Value(number_value=150),\n",
    "        \"distanceMeasureType\": struct_pb2.Value(string_value=\"DOT_PRODUCT_DISTANCE\"),\n",
    "        \"algorithmConfig\": struct_pb2.Value(struct_value=algorithmConfig),\n",
    "        \"shardSize\": struct_pb2.Value(string_value=\"SHARD_SIZE_SMALL\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"config\": struct_pb2.Value(struct_value=config),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(string_value=EMBEDDINGS_INITIAL_URI),\n",
    "    }\n",
    ")\n",
    "\n",
    "ann_index = {\n",
    "    \"display_name\": DISPLAY_NAME_BRUTE_FORCE,\n",
    "    \"description\": \"Glove 100 index (brute force) - stream\",\n",
    "    \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "    \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.STREAM_UPDATE,\n",
    "}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index = index_client.create_index(parent=PARENT, index=ann_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_BRUTE_FORCE_RESOURCE_NAME = ann_index.result().name\n",
    "INDEX_BRUTE_FORCE_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already created an index, set the index resource name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDEX_BRUTE_FORCE_RESOURCE_NAME = \"4679758982326255616\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the resource name, you can retrieve an existing MatchingEngineIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "865fcad494d7"
   },
   "outputs": [],
   "source": [
    "brute_force_index = aiplatform.MatchingEngineIndex(\n",
    "    index_name=INDEX_BRUTE_FORCE_RESOURCE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other quick notes on ME while we wait for deployment\n",
    "\n",
    "[Blog Link on the technology](https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology)\n",
    "\n",
    "Instead of comparing vectors one by one, you could use the approximate nearest neighbor (ANN) approach to improve search times. Many ANN algorithms use vector quantization (VQ), in which you split the vector space into multiple groups, define \"codewords\" to represent each group, and search only for those codewords. This VQ technique dramatically enhances query speeds and is the essential part of many ANN algorithms, just like indexing is the essential part of relational databases and full-text search engines.\n",
    "\n",
    "![](img/vectorQuant.gif)\n",
    "\n",
    "\n",
    "As the number of groups in the space increases the speed of the search decreases and the accuracy increases.  Managing this trade-off — getting higher accuracy at shorter latency — has been a key challenge with ANN algorithms. \n",
    "\n",
    "Last year, Google Research announced ScaNN, a new solution that provides state-of-the-art results for this challenge. With ScaNN, they introduced a new VQ algorithm called anisotropic vector quantization:\n",
    "\n",
    "![](img/Loss_Types.max-1000x1000.png)\n",
    "\n",
    "Anisotropic vector quantization uses a new loss function to train a model for VQ for an optimal grouping to capture farther data points (i.e. higher inner product) in a single group. With this idea, the new algorithm gives you higher accuracy at lower latency, as you can see in the benchmark result below (the violet line): \n",
    "\n",
    "![](img/speedvsaccuracy.max-1600x1600.png)\n",
    "\n",
    "[You can see 20% increase in performance vs. standard SOLR-type algos , 15% ish for FAISS](https://ann-benchmarks.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's also quickly break down the parameters and suggeted settings\n",
    "\n",
    "```python\n",
    "  \"contentsDeltaUri\": \"gs://BUCKET_NAME/path\",\n",
    "  \"config\": {\n",
    "    \"dimensions\": 100,\n",
    "    \"approximateNeighborsCount\": 150,\n",
    "    \"distanceMeasureType\": \"DOT_PRODUCT_DISTANCE\",\n",
    "    \"shardSize\": \"SHARD_SIZE_SMALL\",\n",
    "    \"algorithm_config\": {\n",
    "      \"treeAhConfig\": {\n",
    "        \"leafNodeEmbeddingCount\": 5000,\n",
    "        \"leafNodesToSearchPercent\": 3\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "```\n",
    "\n",
    "- `dimensions` size of the embeddings stored in the index\n",
    "- `approximateNeighborsCount` set this to increase approximate results for a search. Latency increases proprotinately, but recall does as well\n",
    "- `shardSize` defaults to medium, but general rule of thumb is to try to go as large as budget allows - going to a large shard can often help performance\n",
    "- `distanceMeasureType` can be squared l2, l1, cosine, dot product, unit l2\n",
    "\n",
    "#### config details (important still!)\n",
    "- `leafNodeEmbeddingCount` - number of embeddings in each cluster/leaf\n",
    "- `leafNodesToSearchPercent` - the percentage of leaf/clusters searched for any given query - this number is an int but treated as a percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omlgEZ-sGoM5",
    "tags": []
   },
   "source": [
    "## Stream Update Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZU7TU7C7GoM6"
   },
   "source": [
    "#### Note from the PM on Compaction\n",
    "\n",
    "`Periodically, your index is rebuilt to account for all new updates since your last rebuild. This rebuild, or \"compaction\", improves query performance and reliability. Compactions occur for both Streaming Updates and Batch Updates.`\n",
    "\n",
    "```\n",
    "Streaming Update: Occurs when the uncompacted data size is > 1 GB or the oldest uncompacted data is at least three days old. You are billed for the cost of rebuilding the index at the same rate of a batch update, in addition to the Streaming Update costs.\n",
    "Batch Update: Occurs when the incremental dataset size is > 20% of the base dataset size.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Note on autoscaling too\n",
    "\n",
    "Notes from the PM on bursting to large scale (help with big retailer): \n",
    "\n",
    "```\n",
    "We support autoscaling. Just set max-replica-count to a large enough number, ME will respond the the peak load by increasing the number of replicas (gradually). Beneath the surface, autoscaling is handled by GKE (HPA) and scale up happens when the CPU load of existing pods exceeds 50%. That being said, the autocaling can be slow - new pods need 30 - 60 minutes to be ready and the scaling up is like a staircase. Scale down is usually much faster. When the pods are overloaded, the throttle/reject new requests and return RESOURCE_EXHAUSTED errors. If the customer knows when the peak comes, we recommend manual scaling instead - manually update the deployed index to set the min-replica-count to a high enough value\n",
    "```\n",
    "\n",
    "[Link to mutating resource config on an index](https://cloud.google.com/vertex-ai/docs/matching-engine/deploy-index-public#autoscaling)\n",
    "\n",
    "\n",
    "Best resources for QPS\n",
    "\n",
    "n2d-standard-32 is the most powerful machine type we have and it's most cost effective for heavy/batch load.\n",
    "Each n2d-standard-32  can handle 1k - 10k QPS depends on lots of factors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "query = [\n",
    "    -0.11333,\n",
    "    0.48402,\n",
    "    0.090771,\n",
    "    -0.22439,\n",
    "    0.034206,\n",
    "    -0.55831,\n",
    "    0.041849,\n",
    "    -0.53573,\n",
    "    0.18809,\n",
    "    -0.58722,\n",
    "    0.015313,\n",
    "    -0.014555,\n",
    "    0.80842,\n",
    "    -0.038519,\n",
    "    0.75348,\n",
    "    0.70502,\n",
    "    -0.17863,\n",
    "    0.3222,\n",
    "    0.67575,\n",
    "    0.67198,\n",
    "    0.26044,\n",
    "    0.4187,\n",
    "    -0.34122,\n",
    "    0.2286,\n",
    "    -0.53529,\n",
    "    1.2582,\n",
    "    -0.091543,\n",
    "    0.19716,\n",
    "    -0.037454,\n",
    "    -0.3336,\n",
    "    0.31399,\n",
    "    0.36488,\n",
    "    0.71263,\n",
    "    0.1307,\n",
    "    -0.24654,\n",
    "    -0.52445,\n",
    "    -0.036091,\n",
    "    0.55068,\n",
    "    0.10017,\n",
    "    0.48095,\n",
    "    0.71104,\n",
    "    -0.053462,\n",
    "    0.22325,\n",
    "    0.30917,\n",
    "    -0.39926,\n",
    "    0.036634,\n",
    "    -0.35431,\n",
    "    -0.42795,\n",
    "    0.46444,\n",
    "    0.25586,\n",
    "    0.68257,\n",
    "    -0.20821,\n",
    "    0.38433,\n",
    "    0.055773,\n",
    "    -0.2539,\n",
    "    -0.20804,\n",
    "    0.52522,\n",
    "    -0.11399,\n",
    "    -0.3253,\n",
    "    -0.44104,\n",
    "    0.17528,\n",
    "    0.62255,\n",
    "    0.50237,\n",
    "    -0.7607,\n",
    "    -0.071786,\n",
    "    0.0080131,\n",
    "    -0.13286,\n",
    "    0.50097,\n",
    "    0.18824,\n",
    "    -0.54722,\n",
    "    -0.42664,\n",
    "    0.4292,\n",
    "    0.14877,\n",
    "    -0.0072514,\n",
    "    -0.16484,\n",
    "    -0.059798,\n",
    "    0.9895,\n",
    "    -0.61738,\n",
    "    0.054169,\n",
    "    0.48424,\n",
    "    -0.35084,\n",
    "    -0.27053,\n",
    "    0.37829,\n",
    "    0.11503,\n",
    "    -0.39613,\n",
    "    0.24266,\n",
    "    0.39147,\n",
    "    -0.075256,\n",
    "    0.65093,\n",
    "    -0.20822,\n",
    "    -0.17456,\n",
    "    0.53571,\n",
    "    -0.16537,\n",
    "    0.13582,\n",
    "    -0.56016,\n",
    "    0.016964,\n",
    "    0.1277,\n",
    "    0.94071,\n",
    "    -0.22608,\n",
    "    -0.021106,\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_datapoints_payload = aiplatform_v1.IndexDatapoint(\n",
    "    datapoint_id=\"101\",\n",
    "    feature_vector=query,\n",
    "    restricts=[{\"namespace\": \"class\", \"allow_list\": [\"odd\"]}],\n",
    ")\n",
    "\n",
    "upsert_request = aiplatform_v1.UpsertDatapointsRequest(\n",
    "    index=tree_ah_index.resource_name, datapoints=[insert_datapoints_payload]\n",
    ")\n",
    "\n",
    "index_client.upsert_datapoints(request=upsert_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit Datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing restricts namespace value from odd to even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_datapoints_payload = aiplatform_v1.IndexDatapoint(\n",
    "    datapoint_id=\"101\",\n",
    "    feature_vector=query,\n",
    "    restricts=[{\"namespace\": \"class\", \"allow_list\": [\"even\"]}],\n",
    ")\n",
    "\n",
    "upsert_request = aiplatform_v1.UpsertDatapointsRequest(\n",
    "    index=tree_ah_index.resource_name, datapoints=[insert_datapoints_payload]\n",
    ")\n",
    "\n",
    "index_client.upsert_datapoints(request=upsert_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the datapoint with id '101' from the index\n",
    "remove_request = aiplatform_v1.RemoveDatapointsRequest(\n",
    "    index=tree_ah_index.resource_name, datapoint_ids=[\"101\"]\n",
    ")\n",
    "\n",
    "index_client.remove_datapoints(request=remove_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV2xjAnDDObD",
    "tags": []
   },
   "source": [
    "## Create an IndexEndpoint with Private Service Connect (PSC)\n",
    "\n",
    "See [PSC documentation](https://cloud.google.com/vertex-ai/docs/vector-search/setup/private-service-connect) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your desired index endpoint name below, along with the shared VPC where you'd like your index endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_ENDPT_NAME = \"\"\n",
    "SHARED_VPC_PROJECT_ID = \"\"\n",
    "PARENT = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform_v1 import IndexEndpointServiceClient\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint_request = {\"display_name\": INDEX_ENDPT_NAME}\n",
    "index_endpoint_request[\"private_service_connect_config\"] = {\"enable_private_service_connect\": True,\n",
    "                                                                \"project_allowlist\": [PROJECT_ID, SHARED_VPC_PROJECT_ID]}\n",
    "\n",
    "index_endpoint_client = IndexEndpointServiceClient(client_options=dict(api_endpoint=ENDPOINT))\n",
    "\n",
    "r = index_endpoint_client.create_index_endpoint(\n",
    "    parent=PARENT,\n",
    "    index_endpoint=index_endpoint_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if r.done():\n",
    "        break\n",
    "    time.sleep(60)\n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint = r.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "PJ3bcZqi-cfM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_ENDPOINT_NAME = index_endpoint.name\n",
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have an index endpoint created, set the index endpoint name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INDEX_ENDPOINT_NAME=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(INDEX_ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np2cgVuuIe9k"
   },
   "source": [
    "## Deploy Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ew1UgcIIiJG"
   },
   "source": [
    "### Deploy ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "nLOYTGygIlMK"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = \"tree_ah_glove_deployed_unique\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [pricing page](https://cloud.google.com/vertex-ai/pricing#matchingengine) for possible machine types (uses default for shard size if left empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uK4WOgqN1NG",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=tree_ah_index, \n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    min_replica_count=2,\n",
    "    max_replica_count=2,\n",
    "    # machine_type=\"\"\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNZnXmO5AhDO"
   },
   "source": [
    "### Deploy Brute Force Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3p9e4828AkSv"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_BRUTE_FORCE_INDEX_ID = \"glove_brute_force_deployed_unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2kgd01SA4rk",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=brute_force_index, \n",
    "    deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID,\n",
    "    min_replica_count=2,\n",
    "    max_replica_count=2,\n",
    "    # machine_type=\"\"\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LCGvBNvBd8D",
    "tags": []
   },
   "source": [
    "## Create Config Needed for PSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get your service attachament URI from the previous cell's output or directly from the Google Cloud Vertex AI console/UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ATTACHMENT_URI=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work with team who manages your shared VPC to run the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_NAME=\"projects/*/global/networks/*\"\n",
    "ADDRESS_ENDPOINT_NAME=\"vme-psc-svc-for-demo\" # set to whatever you want to name the address and forwarding rule / PSC endpoint\n",
    "REGION=\"us-central1\"\n",
    "SUBNET_NAME=\"projects/*/regions/*/subnetworks/*\"\n",
    "SVC_PROJECT=\"*\" # can be your own project or the shared VPC project depending on where you want to create the IP address and forwarding rule\n",
    "\n",
    "gcloud compute addresses create ${ADDRESS_ENDPOINT_NAME:?} \\\n",
    "    --region=${REGION:?} \\\n",
    "    --subnet=${SUBNET_NAME:?} \\\n",
    "    --project=${SVC_PROJECT:?}\n",
    "\n",
    "gcloud compute forwarding-rules create ${ADDRESS_ENDPOINT_NAME:?} \\\n",
    "    --network=${NETWORK_NAME:?} \\\n",
    "    --address=${ADDRESS_ENDPOINT_NAME:?} \\\n",
    "    --target-service-attachment=${SERVICE_ATTACHMENT_URI:?} \\\n",
    "    --project=${SVC_PROJECT:?} \\\n",
    "    --region=${REGION:?}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LCGvBNvBd8D",
    "tags": []
   },
   "source": [
    "## Create Online Queries\n",
    "\n",
    "After you built your indexes, you may query against the deployed index through the online querying gRPC API (Match service) within the virtual machine instances from the same region (for example 'us-central1' in this tutorial).\n",
    "\n",
    "The `filter` parameter is an optional way to filter for a subset of embeddings. In this case, only embeddings that have the `class` set as `even` are returned.\n",
    "\n",
    "```\n",
    "List[Namespace]\n",
    "Optional. A list of Namespaces for filtering the matching results. For example, [Namespace(\"color\", [\"red\"], []), Namespace(\"shape\", [], [\"squared\"])] will match datapoints that satisfy \"red color\" but not include datapoints with \"squared shape\". Please refer to https://cloud.google.com/vertex-ai/docs/matching-engine/filtering#json for more detail.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_NEIGHBOURS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your IP address that was created in the previous step by the team who manages your shared VPC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPT_IP = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Vertex Python SDK does not support PSC yet, I have recreated the match method with the function below to support passing in an IP address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import MatchNeighbor, Namespace\n",
    "import grpc\n",
    "from google.cloud.aiplatform.matching_engine._protos import match_service_pb2\n",
    "from google.cloud.aiplatform.matching_engine._protos import (\n",
    "    match_service_pb2_grpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vme_grpc_match(endpt_ip, deployed_index_id, n_matches, embeddings, filter=[]):\n",
    "    # Set up channel and stub\n",
    "    channel = grpc.insecure_channel(\"{}:10000\".format(endpt_ip))\n",
    "    stub = match_service_pb2_grpc.MatchServiceStub(channel)\n",
    "\n",
    "    # Create the batch match request\n",
    "    batch_request = match_service_pb2.BatchMatchRequest()\n",
    "    batch_request_for_index = (\n",
    "        match_service_pb2.BatchMatchRequest.BatchMatchRequestPerIndex()\n",
    "    )\n",
    "    batch_request_for_index.deployed_index_id = deployed_index_id\n",
    "    b_requests = []\n",
    "    for query in embeddings:\n",
    "        request = match_service_pb2.MatchRequest(\n",
    "            num_neighbors=n_matches,\n",
    "            deployed_index_id=deployed_index_id,\n",
    "            float_val=query,\n",
    "        )\n",
    "        for namespace in filter:\n",
    "            restrict = match_service_pb2.Namespace()\n",
    "            restrict.name = namespace.name\n",
    "            restrict.allow_tokens.extend(namespace.allow_tokens)\n",
    "            restrict.deny_tokens.extend(namespace.deny_tokens)\n",
    "            request.restricts.append(restrict)\n",
    "        b_requests.append(request)\n",
    "\n",
    "    batch_request_for_index.requests.extend(b_requests)\n",
    "    batch_request.requests.append(batch_request_for_index)\n",
    "\n",
    "    # Perform the request\n",
    "    response = stub.BatchMatch(batch_request)\n",
    "\n",
    "    # Wrap the results in MatchNeighbor objects and return\n",
    "    neighbors = [\n",
    "                    [\n",
    "                        MatchNeighbor(id=neighbor.id, distance=neighbor.distance)\n",
    "                        for neighbor in embedding_neighbors.neighbor\n",
    "                    ]\n",
    "                    for embedding_neighbors in response.responses[0].responses\n",
    "                ]\n",
    "\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='310080', distance=18.029903411865234),\n",
       "  MatchNeighbor(id='702494', distance=16.84667205810547),\n",
       "  MatchNeighbor(id='505832', distance=16.334247589111328),\n",
       "  MatchNeighbor(id='825418', distance=16.22643280029297),\n",
       "  MatchNeighbor(id='436242', distance=16.11363410949707),\n",
       "  MatchNeighbor(id='955052', distance=16.022321701049805),\n",
       "  MatchNeighbor(id='208920', distance=15.804502487182617),\n",
       "  MatchNeighbor(id='380434', distance=15.756570816040039),\n",
       "  MatchNeighbor(id='206918', distance=15.600484848022461),\n",
       "  MatchNeighbor(id='408972', distance=15.564517974853516)],\n",
       " [MatchNeighbor(id='752950', distance=21.807270050048828),\n",
       "  MatchNeighbor(id='690062', distance=19.74156951904297),\n",
       "  MatchNeighbor(id='52842', distance=19.29770278930664),\n",
       "  MatchNeighbor(id='484314', distance=18.903165817260742),\n",
       "  MatchNeighbor(id='317160', distance=18.501405715942383),\n",
       "  MatchNeighbor(id='377396', distance=18.051637649536133),\n",
       "  MatchNeighbor(id='47466', distance=17.993053436279297),\n",
       "  MatchNeighbor(id='310054', distance=17.931102752685547),\n",
       "  MatchNeighbor(id='1031502', distance=17.83464813232422),\n",
       "  MatchNeighbor(id='973082', distance=17.681610107421875)],\n",
       " [MatchNeighbor(id='1087282', distance=21.09122085571289),\n",
       "  MatchNeighbor(id='587106', distance=20.418033599853516),\n",
       "  MatchNeighbor(id='1046944', distance=20.412609100341797),\n",
       "  MatchNeighbor(id='187490', distance=20.1966552734375),\n",
       "  MatchNeighbor(id='1018752', distance=19.673538208007812),\n",
       "  MatchNeighbor(id='912028', distance=19.43124771118164),\n",
       "  MatchNeighbor(id='652860', distance=19.342601776123047),\n",
       "  MatchNeighbor(id='219970', distance=19.2674617767334),\n",
       "  MatchNeighbor(id='248960', distance=19.085472106933594),\n",
       "  MatchNeighbor(id='278716', distance=18.92349624633789)]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, test[:3].tolist(), [Namespace(\"class\", [\"even\"])])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='899605', distance=20.079139709472656),\n",
       "  MatchNeighbor(id='729301', distance=18.31948471069336),\n",
       "  MatchNeighbor(id='1093903', distance=17.839481353759766),\n",
       "  MatchNeighbor(id='296543', distance=16.99886703491211),\n",
       "  MatchNeighbor(id='21495', distance=16.8770694732666),\n",
       "  MatchNeighbor(id='689839', distance=16.852933883666992),\n",
       "  MatchNeighbor(id='518781', distance=16.65009307861328),\n",
       "  MatchNeighbor(id='405251', distance=16.278234481811523),\n",
       "  MatchNeighbor(id='1142011', distance=16.186227798461914),\n",
       "  MatchNeighbor(id='724903', distance=16.18083953857422)]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, test[:1].tolist(), [Namespace(\"class\", [\"odd\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "A3KYVw5HB-4v",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.06 ms ± 152 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "\n",
    "vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, test[:1].tolist(), [Namespace(\"class\", [\"odd\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeUZO3bAGoM-"
   },
   "source": [
    "### Compute Recall\n",
    "\n",
    "Use the deployed brute force Index as the ground truth to calculate the recall of ANN Index. Note that you can run multiple queries in a single match call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "U9dNIbkEGoM-"
   },
   "outputs": [],
   "source": [
    "# Retrieve nearest neighbors for both the tree-AH index and the brute-force index\n",
    "tree_ah_response_test = vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, list(test))\n",
    "\n",
    "brute_force_response_test = vme_grpc_match(ENDPT_IP, DEPLOYED_BRUTE_FORCE_INDEX_ID, NUM_NEIGHBOURS, list(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "V-eMF05UGoM-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5787\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall by determining how many neighbors were correctly retrieved as compared to the brute-force option.\n",
    "recalled_neighbors = 0\n",
    "for tree_ah_neighbors, brute_force_neighbors in zip(\n",
    "    tree_ah_response_test, brute_force_response_test\n",
    "):\n",
    "    tree_ah_neighbor_ids = [neighbor.id for neighbor in tree_ah_neighbors]\n",
    "    brute_force_neighbor_ids = [neighbor.id for neighbor in brute_force_neighbors]\n",
    "\n",
    "    recalled_neighbors += len(\n",
    "        set(tree_ah_neighbor_ids).intersection(brute_force_neighbor_ids)\n",
    "    )\n",
    "\n",
    "recall = recalled_neighbors / len(\n",
    "    [neighbor for neighbors in brute_force_response_test for neighbor in neighbors]\n",
    ")\n",
    "\n",
    "print(\"Recall: {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "You can also manually delete resources that you created by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying MatchingEngineIndexEndpoint index_endpoint: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Undeploy MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552/operations/6281238006514843648\n",
      "MatchingEngineIndexEndpoint index_endpoint undeployed. Resource name: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Undeploying MatchingEngineIndexEndpoint index_endpoint: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Undeploy MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552/operations/3707430819472605184\n",
      "MatchingEngineIndexEndpoint index_endpoint undeployed. Resource name: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Deleting MatchingEngineIndexEndpoint : projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Delete MatchingEngineIndexEndpoint  backing LRO: projects/1023019892523/locations/us-central1/operations/5434561276569190400\n",
      "MatchingEngineIndexEndpoint deleted. . Resource name: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n"
     ]
    }
   ],
   "source": [
    "# Force undeployment of indexes and delete endpoint\n",
    "my_index_endpoint.delete(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "omj7N9iWv-Tq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting MatchingEngineIndex : projects/679926387543/locations/us-central1/indexes/5615205883052032000\n",
      "Delete MatchingEngineIndex  backing LRO: projects/679926387543/locations/us-central1/indexes/5615205883052032000/operations/1323186583884529664\n",
      "MatchingEngineIndex deleted. . Resource name: projects/679926387543/locations/us-central1/indexes/5615205883052032000\n",
      "Deleting MatchingEngineIndex : projects/679926387543/locations/us-central1/indexes/1901987990285058048\n",
      "Delete MatchingEngineIndex  backing LRO: projects/679926387543/locations/us-central1/indexes/1901987990285058048/operations/6778734582490464256\n",
      "MatchingEngineIndex deleted. . Resource name: projects/679926387543/locations/us-central1/indexes/1901987990285058048\n"
     ]
    }
   ],
   "source": [
    "# Delete indexes\n",
    "tree_ah_index.delete()\n",
    "brute_force_index.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sdk_matching_engine_for_indexing.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3 (vme) (Local)",
   "language": "python",
   "name": "local-conda-env-vme-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
